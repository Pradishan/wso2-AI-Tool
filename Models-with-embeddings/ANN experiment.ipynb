{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e3622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import numpy as np\n",
    "\n",
    "import keras_tuner as kt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- NN Configuration ---\n",
    "# We'll use these for the baseline experiments\n",
    "NN_EPOCHS = 100\n",
    "NN_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89219f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File Paths ---\n",
    "SOURCE_DATASET_PATH = \"data/final_dataset_with_embeddings.csv\" # Your final dataset with embeddings\n",
    "BASE_LOG_DIR = \"logs\" # A parent directory to store all results\n",
    "\n",
    "# --- Feature Configuration ---\n",
    "METADATA_COLS = [\"commit_hash\", \"author_email\", \"commit_date\"]\n",
    "LABEL_COL = \"is_bug_introducing\"\n",
    "N_PCA_COMPONENTS = 177 # The optimal number you found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03230427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_data(path):\n",
    "    \"\"\"Loads the source CSV, cleans it, and sorts by date.\"\"\"\n",
    "    print(f\"Loading and preparing base data from '{path}'...\")\n",
    "    df = pd.read_csv(path)\n",
    "    df.dropna(subset=['commit_hash', LABEL_COL], inplace=True)\n",
    "    df[\"commit_date\"] = pd.to_datetime(df[\"commit_date\"])\n",
    "    df.sort_values(by=\"commit_date\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Base data loaded successfully.\")\n",
    "    return df\n",
    "\n",
    "def prepare_feature_sets(df):\n",
    "    \"\"\"Creates all the different feature combinations for our experiments.\"\"\"\n",
    "    print(\"Preparing all feature sets...\")\n",
    "    \n",
    "    embedding_cols = [col for col in df.columns if col.startswith('emb_')]\n",
    "    stats_cols = [col for col in df.columns if col not in embedding_cols + METADATA_COLS + [LABEL_COL]]\n",
    "    \n",
    "    # Normalize and apply PCA to embeddings\n",
    "    X_embed = df[embedding_cols].values\n",
    "    X_normalized = Normalizer(norm='l2').fit_transform(X_embed)\n",
    "    pca = PCA(n_components=N_PCA_COMPONENTS, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_normalized)\n",
    "    \n",
    "    pca_cols = [f'pca_{i+1}' for i in range(N_PCA_COMPONENTS)]\n",
    "    df_pca = pd.DataFrame(X_pca, columns=pca_cols)\n",
    "\n",
    "    feature_sets = {\n",
    "        \"stats_only\": df[stats_cols],\n",
    "        \"embeddings_only\": df[embedding_cols],\n",
    "        \"pca_only\": df_pca,\n",
    "        \"stats_and_embeddings\": pd.concat([df[stats_cols], df[embedding_cols]], axis=1),\n",
    "        \"stats_and_pca\": pd.concat([df[stats_cols], df_pca], axis=1)\n",
    "    }\n",
    "    \n",
    "    print(\"All feature sets are ready.\")\n",
    "    return feature_sets, df[LABEL_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e077a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_nn(input_shape):\n",
    "    \"\"\"Defines and compiles a standard baseline Neural Network.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid') # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def run_nn_experiment(experiment_name, X_data, y_data):\n",
    "    \"\"\"Runs a baseline NN experiment for a given feature set and logs to MLflow.\"\"\"\n",
    "    print(f\"\\n--- Running Experiment: {experiment_name} ---\")\n",
    "    \n",
    "    # 1. Create dedicated directories\n",
    "    results_dir = os.path.join(BASE_LOG_DIR, experiment_name)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # 2. Split and scale data\n",
    "    split_point = int(len(X_data) * 0.80)\n",
    "    X_train, X_test = X_data.iloc[:split_point], X_data.iloc[split_point:]\n",
    "    y_train, y_test = y_data.iloc[:split_point], y_data.iloc[split_point:]\n",
    "    \n",
    "    # Neural networks benefit from feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 3. Set up MLflow\n",
    "    mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        # 4. Create and train the model\n",
    "        model = create_baseline_nn(X_train_scaled.shape[1])\n",
    "        \n",
    "        # Handle class imbalance\n",
    "        neg, pos = np.bincount(y_train)\n",
    "        class_weight = {0: (1 / neg) * (len(y_train) / 2.0), 1: (1 / pos) * (len(y_train) / 2.0)}\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train_scaled,\n",
    "            y_train,\n",
    "            epochs=NN_EPOCHS,\n",
    "            batch_size=NN_BATCH_SIZE,\n",
    "            validation_data=(X_test_scaled, y_test),\n",
    "            class_weight=class_weight,\n",
    "            verbose=0 # Suppress output during training\n",
    "        )\n",
    "        \n",
    "        # 5. Evaluate and log metrics\n",
    "        y_pred_proba = model.predict(X_test_scaled).ravel()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        metrics = {\n",
    "            \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "            \"roc_auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "            \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"--- Experiment '{experiment_name}' Complete ---\")\n",
    "        print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b18383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing base data from 'data/final_dataset_with_embeddings.csv'...\n",
      "Base data loaded successfully.\n",
      "Preparing all feature sets...\n",
      "All feature sets are ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Load data and create all feature sets once ---\n",
    "base_df = load_base_data(SOURCE_DATASET_PATH)\n",
    "all_feature_sets, y_data = prepare_feature_sets(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc55abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment: NN_Stats_Only ---\n",
      "79/79 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:38:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/23 08:38:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PRADIS~1\\AppData\\Local\\Temp\\tmpcfcen7e5\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:38:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment 'NN_Stats_Only' Complete ---\n",
      "F1 Score: 0.2609\n",
      "ROC AUC: 0.6014\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 1: Stats Only ---\n",
    "run_nn_experiment(\n",
    "    experiment_name=\"NN_Stats_Only\",\n",
    "    X_data=all_feature_sets[\"stats_only\"],\n",
    "    y_data=y_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694d9790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment: NN_Embeddings_Only ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:38:45 INFO mlflow.tracking.fluent: Experiment with name 'NN_Embeddings_Only' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:40:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/23 08:40:09 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PRADIS~1\\AppData\\Local\\Temp\\tmpqbjkk68j\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:40:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment 'NN_Embeddings_Only' Complete ---\n",
      "F1 Score: 0.2996\n",
      "ROC AUC: 0.6456\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 2: Embeddings Only ---\n",
    "run_nn_experiment(\n",
    "    experiment_name=\"NN_Embeddings_Only\",\n",
    "    X_data=all_feature_sets[\"embeddings_only\"],\n",
    "    y_data=y_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a095587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment: NN_PCA_Only ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:40:22 INFO mlflow.tracking.fluent: Experiment with name 'NN_PCA_Only' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:41:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/23 08:41:51 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PRADIS~1\\AppData\\Local\\Temp\\tmphgx2cn2v\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:42:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment 'NN_PCA_Only' Complete ---\n",
      "F1 Score: 0.2732\n",
      "ROC AUC: 0.6308\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 3: PCA-Reduced Embeddings Only ---\n",
    "run_nn_experiment(\n",
    "    experiment_name=\"NN_PCA_Only\",\n",
    "    X_data=all_feature_sets[\"pca_only\"],\n",
    "    y_data=y_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e95d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment: NN_Stats_and_Embeddings ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:42:08 INFO mlflow.tracking.fluent: Experiment with name 'NN_Stats_and_Embeddings' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:43:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/23 08:43:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PRADIS~1\\AppData\\Local\\Temp\\tmp5zk6bpgp\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:43:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment 'NN_Stats_and_Embeddings' Complete ---\n",
      "F1 Score: 0.3209\n",
      "ROC AUC: 0.6725\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 4: Stats + Full Embeddings ---\n",
    "run_nn_experiment(\n",
    "    experiment_name=\"NN_Stats_and_Embeddings\",\n",
    "    X_data=all_feature_sets[\"stats_and_embeddings\"],\n",
    "    y_data=y_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca6b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:43:42 INFO mlflow.tracking.fluent: Experiment with name 'NN_Stats_and_PCA' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment: NN_Stats_and_PCA ---\n",
      "79/79 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:44:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/23 08:44:58 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PRADIS~1\\AppData\\Local\\Temp\\tmpy45bjx19\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 08:45:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment 'NN_Stats_and_PCA' Complete ---\n",
      "F1 Score: 0.2910\n",
      "ROC AUC: 0.6517\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 5: Stats + PCA-Reduced Embeddings ---\n",
    "run_nn_experiment(\n",
    "    experiment_name=\"NN_Stats_and_PCA\",\n",
    "    X_data=all_feature_sets[\"stats_and_pca\"],\n",
    "    y_data=y_data\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
