{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ab30f8",
   "metadata": {},
   "source": [
    "# Random foreset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f4c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e98894",
   "metadata": {},
   "source": [
    "Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223b3551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a grid with 36 hyperparameter combinations to test.\n"
     ]
    }
   ],
   "source": [
    "# Define the grid of hyperparameters to search over\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300, 500],            # More trees → better generalization, higher cost\n",
    "#     'max_depth': [None, 10, 20, 30],                 # Controls overfitting; None lets trees grow fully\n",
    "#     'min_samples_split': [2, 5, 10],                 # Higher values → more conservative splits\n",
    "#     'min_samples_leaf': [1, 2, 4],                   # Ensures enough samples at each leaf to reduce noise\n",
    "#     'max_features': ['sqrt', 'log2', None],          # Controls number of features to consider per split\n",
    "#     'bootstrap': [True, False],                      # Whether sampling is with replacement\n",
    "#     'class_weight': [None, 'balanced'],              # Essential for imbalanced datasets\n",
    "#     'criterion': ['gini', 'entropy'],                # Different impurity measures for split quality\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None,10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "}\n",
    "\n",
    "# Create a list of all possible combinations\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "print(f\"Created a grid with {len(grid)} hyperparameter combinations to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7087b",
   "metadata": {},
   "source": [
    "Load and Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e9bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradishan\\AppData\\Local\\Temp\\ipykernel_24292\\1828121981.py:3: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df[\"commit_date\"] = pd.to_datetime(df[\"commit_date\"])\n"
     ]
    }
   ],
   "source": [
    "FINAL_DATASET_PATH = \"../data/final/final_labeled_training_dataset.csv\"\n",
    "df = pd.read_csv(FINAL_DATASET_PATH)\n",
    "df[\"commit_date\"] = pd.to_datetime(df[\"commit_date\"])\n",
    "df.sort_values(by=\"commit_date\", inplace=True)\n",
    "\n",
    "X = df.drop(\n",
    "    columns=[\"commit_hash\", \"author_email\", \"commit_date\", \"is_bug_introducing\"]\n",
    ")\n",
    "y = df[\"is_bug_introducing\"]\n",
    "\n",
    "split_point = int(len(df) * 0.80)\n",
    "X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]\n",
    "y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86eb20",
   "metadata": {},
   "source": [
    "SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2010ad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pradishan\\code\\wso2-AI-Tool\\.venv\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set class distribution:\n",
      " is_bug_introducing\n",
      "0    66588\n",
      "1    34072\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resampled training set class distribution:\n",
      " is_bug_introducing\n",
      "0    66588\n",
      "1    66588\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original training set class distribution:\\n\", y_train.value_counts())\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"\\nResampled training set class distribution:\\n\", y_train_resampled.value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3aca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hparams_for_logging(params):\n",
    "    hparams_for_log = {}\n",
    "    for key, value in params.items():\n",
    "        if value is None:\n",
    "            hparams_for_log[key] = \"None\"  # Convert to string\n",
    "        elif isinstance(value, (int, float, bool)):\n",
    "            hparams_for_log[key] = value\n",
    "        else:\n",
    "            hparams_for_log[key] = str(value)\n",
    "    return hparams_for_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d385b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Comprehensive Hyperparameter Search ---\n",
      "Created log directory at: c:\\Users\\pradishan\\code\\wso2-AI-Tool\\statistical-model\\logs\\runs\\rf_grid_search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  14%|█▍        | 5/36 [02:28<15:22, 29.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# --- Evaluate the model ---\u001b[39;00m\n\u001b[0;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 30\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     32\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m     33\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pradishan\\code\\wso2-AI-Tool\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:957\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    952\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    953\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m    955\u001b[0m ]\n\u001b[0;32m    956\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 957\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m    963\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32mc:\\Users\\pradishan\\code\\wso2-AI-Tool\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pradishan\\code\\wso2-AI-Tool\\.venv\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pradishan\\code\\wso2-AI-Tool\\.venv\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pradishan\\code\\wso2-AI-Tool\\.venv\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting Comprehensive Hyperparameter Search ---\")\n",
    "\n",
    "# Create absolute path for logs\n",
    "base_log_dir = os.path.join(os.getcwd(), \"logs\", \"runs\", \"rf_grid_search\")\n",
    "\n",
    "# Create base directory\n",
    "os.makedirs(base_log_dir, exist_ok=True)\n",
    "print(f\"Created log directory at: {base_log_dir}\")\n",
    "\n",
    "for i, params in enumerate(tqdm(grid, desc=\"Training Models\")):\n",
    "    # Create a simpler run name using an index\n",
    "    run_name = f\"run_{i:04d}\"  # This will create names like run_0000, run_0001, etc.\n",
    "    log_dir = os.path.join(base_log_dir, run_name)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # --- Train the model and time it ---\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1, **params)\n",
    "\n",
    "    start_time = time.time()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    training_duration = end_time - start_time\n",
    "\n",
    "    # --- Evaluate the model ---\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # --- Log all metrics and artifacts to TensorBoard ---\n",
    "    hparams_for_log = prepare_hparams_for_logging(params)\n",
    "    run_name=f\"run_{i:04d}\"\n",
    "\n",
    "    # 1. Log individual scalar metrics\n",
    "    writer.add_scalar(\"Metrics/Accuracy\", accuracy, 1)\n",
    "    writer.add_scalar(\"Metrics/Precision\", precision, 1)\n",
    "    writer.add_scalar(\"Metrics/Recall\", recall, 1)\n",
    "    writer.add_scalar(\"Metrics/F1_Score\", f1, 1)\n",
    "    writer.add_scalar(\"Metrics/ROC_AUC\", roc_auc, 1)\n",
    "    writer.add_scalar(\"Performance/Training_Duration_sec\", training_duration, 1)\n",
    "\n",
    "    # Only hyperparameters go here\n",
    "    hparam_dict = hparams_for_log\n",
    "\n",
    "    # Only evaluation results go here\n",
    "    metric_dict = {\n",
    "        \"hparam/accuracy\": accuracy,\n",
    "        \"hparam/precision\": precision,\n",
    "        \"hparam/recall\": recall,\n",
    "        \"hparam/f1\": f1,\n",
    "        \"hparam/roc_auc\": roc_auc,\n",
    "        \"hparam/training_duration\": training_duration,\n",
    "    }\n",
    "\n",
    "    # 3. Log everything to the HParams dashboard for easy comparison\n",
    "    writer.add_hparams(\n",
    "        hparam_dict={\n",
    "            **hparam_dict,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"training_duration\": training_duration,\n",
    "        },\n",
    "        metric_dict=metric_dict,\n",
    "        run_name=f\"run_{i:04d}\",\n",
    "    )\n",
    "\n",
    "    # 2. Log the feature importance plot\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame(\n",
    "        {\"feature\": X_train.columns, \"importance\": importances}\n",
    "    ).sort_values(by=\"importance\", ascending=True)  # Ascending for horizontal plot\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.barh(\n",
    "        feature_importance_df[\"feature\"], feature_importance_df[\"importance\"], color=\"c\"\n",
    "    )\n",
    "    ax.set_title(f\"Feature Importance (Run {i:04d})\")\n",
    "    writer.add_figure(\"Charts/Feature_Importance\", fig, 1)\n",
    "    plt.close(fig)  # Close the plot to prevent it from displaying in the notebook\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "print(\"\\n--- Hyperparameter Search Complete ---\")\n",
    "print(\n",
    "    \"All results, including feature importance plots, have been logged to TensorBoard.\"\n",
    ")\n",
    "print(f\"Log directory: {base_log_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
