{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ab30f8",
   "metadata": {},
   "source": [
    "# Random foreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8e4495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary libraries if you haven't already\n",
    "# !pip install tensorboard torch\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b94c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard log directory created at: runs/szz_experiment_1752039287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradishan\\AppData\\Local\\Temp\\ipykernel_19236\\3779704766.py:15: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['commit_date'] = pd.to_datetime(df['commit_date'])\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "FINAL_DATASET_PATH = \"../data/final/final_labeled_training_dataset.csv\"\n",
    "N_ESTIMATORS = 200\n",
    "TEST_SPLIT_RATIO = 0.20\n",
    "\n",
    "# --- Set up TensorBoard ---\n",
    "# Create a unique log directory for this run using a timestamp\n",
    "log_dir = f\"runs/szz_experiment_{int(time.time())}\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "print(f\"TensorBoard log directory created at: {log_dir}\")\n",
    "\n",
    "\n",
    "# --- Load and Split Data ---\n",
    "df = pd.read_csv(FINAL_DATASET_PATH)\n",
    "df['commit_date'] = pd.to_datetime(df['commit_date'])\n",
    "df.sort_values(by='commit_date', inplace=True)\n",
    "\n",
    "X = df.drop(columns=['commit_hash', 'author_email', 'commit_date', 'is_bug_introducing'])\n",
    "y = df['is_bug_introducing']\n",
    "\n",
    "split_point = int(len(df) * (1 - TEST_SPLIT_RATIO))\n",
    "X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]\n",
    "y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2010ad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set class distribution:\n",
      " is_bug_introducing\n",
      "0    66588\n",
      "1    34072\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pradishan\\code\\wso2-AI-Tool\\.venv\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled training set class distribution:\n",
      " is_bug_introducing\n",
      "0    66588\n",
      "1    66588\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original training set class distribution:\\n\", y_train.value_counts())\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nResampled training set class distribution:\\n\", y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d385b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Random Forest model...\n",
      "Model training complete. ✅\n",
      "\n",
      "Evaluating model and logging to TensorBoard...\n",
      "\n",
      "--- Results ---\n",
      "Precision: 0.459\n",
      "Recall:    0.702\n",
      "F1-Score:  0.555\n",
      "\n",
      "✅ Results successfully logged to TensorBoard.\n"
     ]
    }
   ],
   "source": [
    "# --- Train Model ---\n",
    "rf_model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=42, n_jobs=-1)\n",
    "print(\"\\nTraining the Random Forest model...\")\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "print(\"Model training complete. ✅\")\n",
    "\n",
    "# --- Evaluate and Log to TensorBoard ---\n",
    "print(\"\\nEvaluating model and logging to TensorBoard...\")\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Log metrics as scalars\n",
    "writer.add_scalar(\"Test/Precision\", precision, 1)\n",
    "writer.add_scalar(\"Test/Recall\", recall, 1)\n",
    "writer.add_scalar(\"Test/F1_Score\", f1, 1)\n",
    "\n",
    "# Log hyperparameters and final metrics together for easy comparison\n",
    "hparams = {\"n_estimators\": N_ESTIMATORS, \"test_split_ratio\": TEST_SPLIT_RATIO}\n",
    "metrics = {\"hparam/precision\": precision, \"hparam/recall\": recall, \"hparam/f1\": f1}\n",
    "writer.add_hparams(hparams, metrics)\n",
    "\n",
    "# Close the writer to ensure everything is saved\n",
    "writer.close()\n",
    "\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-Score:  {f1:.3f}\")\n",
    "print(\"\\n✅ Results successfully logged to TensorBoard.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
